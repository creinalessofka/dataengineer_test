{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART 1: SQL\n",
        "\n",
        "There are two tables in the included database\n",
        "\n",
        "1. train_table\n",
        "2. test_table\n",
        "\n",
        "\n",
        "IMPORTANT: No other libraries are allowed to solve this tests only SQL Queries allowed\n",
        "\n",
        "* pandas methods are not is not allowed\n",
        "* sqlalchemy is not allowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only library allowed do not modify\n",
        "import pandas as pd\n",
        "from src.sql import execute_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#example query inside docstring\n",
        "execute_query(\"\"\"\n",
        "        SELECT * \n",
        "        FROM train_table\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#example query inside docstring\n",
        "execute_query(\"\"\"\n",
        "        SELECT * \n",
        "        FROM test_table\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## question 1: Basic SQL\n",
        "Write a SQL statement from table <i>train_table</i> to obtain the top 10 <i>locations</i> people twit from (in descending order)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "EXAMPLE SOLUTION:\n",
        "\n",
        "   UserName          Location  count\n",
        "0     11756       Doha, Qatar     10\n",
        "..\n",
        "8       450    The Colony, TX      9\n",
        "9     14693  Brighton Lass ??      8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_1 = \"\"\"\n",
        "SELECT\n",
        "    UserName, \n",
        "    Location,\n",
        "    COUNT(*) AS tweet_count\n",
        "FROM train_table\n",
        "WHERE Location IS NOT NULL \n",
        "GROUP BY Location\n",
        "ORDER BY tweet_count DESC\n",
        "LIMIT 10;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "result_1 = execute_query(query_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2: Intermediate SQL"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "You are tasked to build a dataset that contains the count of Sentiment values as columns for every UserName.\n",
        "\n",
        "The dataset must contain the following columns and name convention:\n",
        "    0. UserName (int)\n",
        "    1. pos_count (int)\n",
        "    2. neg_count (int)\n",
        "    3. extremely_pos_count (int)\n",
        "    4. extremely_neg_count (int)\n",
        "\n",
        "EXAMPLE SOLUTION:\n",
        "\n",
        "\n",
        "   UserName  pos_count  neg_count  extremely_pos_count  extremely_neg_count\n",
        "0     14675          1          7                    1                    0\n",
        "1     12457          1          5                    0                    0\n",
        "...\n",
        "9     14405          0          4                    0                    1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_2 = \"\"\"\n",
        "SELECT\n",
        "    UserName,\n",
        "    SUM(CASE WHEN Sentiment = 'Positive' THEN 1 ELSE 0 END) AS pos_count,\n",
        "    SUM(CASE WHEN Sentiment = 'Negative' THEN 1 ELSE 0 END) AS neg_count,\n",
        "    SUM(CASE WHEN Sentiment = 'Extremely Positive' THEN 1 ELSE 0 END) AS extremely_pos_count,\n",
        "    SUM(CASE WHEN Sentiment = 'Extremely Negative' THEN 1 ELSE 0 END) AS extremely_neg_count\n",
        "FROM train_table\n",
        "GROUP BY UserName;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_2 = execute_query(query_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: Medium SQL"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "The sales department asks you to plot the positive sentiment rate in time\n",
        "\n",
        "The positive sentiment rate is defined as: \n",
        "\n",
        "    (count of positives + count of extremely positives) / [(count of negatives + count of extremely negatives) + (count of positives + count of extremely positives)]\n",
        "\n",
        "requirement:\n",
        "\n",
        "1. positive rate column most be named pos_rate\n",
        "\n",
        "\n",
        "\n",
        "EXAMPLE SOLUTION:\n",
        "\n",
        "\n",
        "\ttweetAt\t    pos_rate\n",
        "0\t18-03-2020\t1.000000\n",
        "1\t21-03-2020\t1.000000\n",
        "...\n",
        "4\t18-03-2020\t0.777778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_3 = \"\"\"\n",
        "--(count of positives + count of extremely positives) / [(count of negatives + count of extremely negatives) + (count of positives + count of extremely positives)]\n",
        "SELECT\n",
        "    TweetAt,\n",
        "    (\n",
        "        (\n",
        "            SUM(CASE WHEN Sentiment = 'Positive' THEN 1 ELSE 0 END)\n",
        "            + SUM(CASE WHEN Sentiment = 'Extremely Positive' THEN 1 ELSE 0 END)\n",
        "        ) * 1.0\n",
        "            /\n",
        "        (\n",
        "            SUM(CASE WHEN Sentiment IN ('Positive', 'Extremely Positive') THEN 1 ELSE 0 END)\n",
        "            + SUM(CASE WHEN Sentiment IN ('Negative', 'Extremely Negative') THEN 1 ELSE 0 END)\n",
        "        )\n",
        "    ) AS pos_rate\n",
        "FROM train_table\n",
        "GROUP BY TweetAt\n",
        "ORDER BY TweetAt;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_3 = execute_query(query_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4: SQL + pandas + plotting"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "You are tasked to deliver a simple plot a time series of the answer of Question 3\n",
        "\n",
        "Requirements:\n",
        "    1. the proceedure most take the result_3 variable as input and return nothing\n",
        "    2. the plot most be resampled by day aggregated by the mean\n",
        "    3. no other library like matplotlib can be used only pandas plot interface pd.Series.plot()\n",
        "    4. the date column from result_3 most be parsed into datetime format using pandas built in method.\n",
        "    5. the proceedure must not transform or modify the original result_3 variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Expected result:</p>\n",
        "<img src=\"data/plot_result.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot(df : pd.DataFrame):\n",
        "    #TODO: YOUR CODE GOES HERE\n",
        "    # Make a copy so we don't modify the original result_3 DataFrame\n",
        "    temp_df = df.copy()\n",
        "\n",
        "    # Convert the tweetAt column to datetime (requirement #4)\n",
        "    temp_df[\"TweetAt\"] = pd.to_datetime(temp_df[\"TweetAt\"], format=\"%d-%m-%Y\")\n",
        "\n",
        "    # Set the datetime column as the index\n",
        "    temp_df.set_index('TweetAt', inplace=True)\n",
        "\n",
        "    # Resample by day, aggregating by mean (requirement #2)\n",
        "    daily_df = temp_df.resample('D').mean()\n",
        "\n",
        "    # Plot the pos_rate time series using only pandas plot interface (requirement #3)\n",
        "    daily_df['pos_rate'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot(result_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART 2: Object Oriented Programming + Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from math import sqrt\n",
        "\n",
        "class Data:\n",
        "    \"\"\"\n",
        "    This class holds the CSV data internally and provides:\n",
        "      1) a mechanism to infer dtypes of each column,\n",
        "      2) a method to describe() numerical columns (mean, std, min, max).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, header, rows):\n",
        "        \"\"\"\n",
        "        :param header: list of column names\n",
        "        :param rows: list of lists, where each sublist is a row of CSV data\n",
        "        \"\"\"\n",
        "        self.header = header\n",
        "        self.data = {}  # This dict will map {column_name: [col_values]}\n",
        "        self.dtypes = {}  # Will store the inferred data types per column\n",
        "\n",
        "        # Initialize self.data with an empty list for each column\n",
        "        for col_name in self.header:\n",
        "            self.data[col_name] = []\n",
        "\n",
        "        # Populate self.data by columns\n",
        "        for row in rows:\n",
        "            for col_name, col_val in zip(self.header, row):\n",
        "                self.data[col_name].append(col_val)\n",
        "\n",
        "        # Infer data types after the data has been stored\n",
        "        self.dtypes = self.infer_dtypes()\n",
        "    \n",
        "    def infer_dtypes(self) -> dict:\n",
        "        \"\"\"\n",
        "        Infers the data types of each column distinguishing between date, integer, or float.\n",
        "        If a column fails all numeric/date checks, it will be considered 'string'.\n",
        "\n",
        "        Returns: dict of the form { column_name: \"date\"/\"integer\"/\"float\"/\"string\" }\n",
        "        \"\"\"\n",
        "        inferred = {}\n",
        "\n",
        "        for col_name, values in self.data.items():\n",
        "            # We'll do integer -> float -> date -> string checks.\n",
        "\n",
        "            # 1) Check integer possibility\n",
        "            if self._all_integers(values):\n",
        "                inferred[col_name] = \"integer\"\n",
        "                continue\n",
        "\n",
        "            # 2) Check float possibility\n",
        "            if self._all_floats(values):\n",
        "                inferred[col_name] = \"float\"\n",
        "                continue\n",
        "\n",
        "            # 3) Check date possibility (assuming \"%d-%m-%Y\")\n",
        "            if self._all_dates(values, date_format=\"%d-%m-%Y\"):\n",
        "                inferred[col_name] = \"date\"\n",
        "                continue\n",
        "\n",
        "            # If none matched, store as string\n",
        "            inferred[col_name] = \"string\"\n",
        "\n",
        "        return inferred\n",
        "\n",
        "    def describe(self) -> dict:\n",
        "        \"\"\"\n",
        "        Returns basic statistics of each numerical column: mean, std, max, min.\n",
        "\n",
        "        Example output:\n",
        "            {\n",
        "                \"col_name\": {\n",
        "                    \"mean\": float,\n",
        "                    \"std\": float,\n",
        "                    \"min\": float,\n",
        "                    \"max\": float\n",
        "                },\n",
        "                ...\n",
        "            }\n",
        "        \"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        for col_name, col_dtype in self.dtypes.items():\n",
        "            if col_dtype in (\"integer\", \"float\"):\n",
        "                # Gather non-NaN numeric values\n",
        "                numeric_values = []\n",
        "                for val in self.data[col_name]:\n",
        "                    # We may have replaced errors with 'NaN' (string), so skip them\n",
        "                    if val == \"NaN\":\n",
        "                        continue\n",
        "                    if isinstance(val, int) or isinstance(val, float):\n",
        "                        numeric_values.append(val)\n",
        "                    else:\n",
        "                        # If stored as string but declared numeric, try to parse\n",
        "                        try:\n",
        "                            numeric_values.append(float(val))\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                if len(numeric_values) == 0:\n",
        "                    # If no valid numeric data, skip the stats\n",
        "                    continue\n",
        "\n",
        "                col_mean = sum(numeric_values) / len(numeric_values)\n",
        "                # Calculate sample standard deviation\n",
        "                variance = (\n",
        "                    sum((x - col_mean)**2 for x in numeric_values) / (len(numeric_values) - 1)\n",
        "                    if len(numeric_values) > 1 else 0.0\n",
        "                )\n",
        "                col_std = sqrt(variance)\n",
        "                col_min = min(numeric_values)\n",
        "                col_max = max(numeric_values)\n",
        "\n",
        "                stats[col_name] = {\n",
        "                    \"mean\": col_mean,\n",
        "                    \"std\": col_std,\n",
        "                    \"min\": col_min,\n",
        "                    \"max\": col_max\n",
        "                }\n",
        "        return stats\n",
        "\n",
        "    @staticmethod\n",
        "    def _all_integers(values):\n",
        "        \"\"\"\n",
        "        Return True if every non-\"NaN\" value can be parsed as integer.\n",
        "        \"\"\"\n",
        "        for val in values:\n",
        "            if val == \"NaN\":\n",
        "                continue\n",
        "            try:\n",
        "                int(val)\n",
        "            except ValueError:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def _all_floats(values):\n",
        "        \"\"\"\n",
        "        Return True if every non-\"NaN\" value can be parsed as float.\n",
        "        \"\"\"\n",
        "        for val in values:\n",
        "            if val == \"NaN\":\n",
        "                continue\n",
        "            try:\n",
        "                float(val)\n",
        "            except ValueError:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def _all_dates(values, date_format=\"%Y-%m-%d\"):\n",
        "        \"\"\"\n",
        "        Return True if every non-\"NaN\" value can be parsed as a date\n",
        "        using the given format.\n",
        "        \"\"\"\n",
        "        for val in values:\n",
        "            if val == \"NaN\":\n",
        "                continue\n",
        "            try:\n",
        "                datetime.strptime(val, date_format)\n",
        "            except ValueError:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "class DataReader:\n",
        "    \"\"\"\n",
        "    Responsible for reading a CSV file (with potential errors) into a Data object,\n",
        "    replacing errors with 'NaN' if possible, or dropping rows ONLY if absolutely necessary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def read_csv(self, file_path: str) -> 'Data':\n",
        "        rows = []\n",
        "        header = []\n",
        "\n",
        "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            first_line = True\n",
        "\n",
        "            for row in reader:\n",
        "                if first_line:\n",
        "                    header = row\n",
        "                    first_line = False\n",
        "                    continue\n",
        "\n",
        "                # Align to the length of the header\n",
        "                if len(row) < len(header):\n",
        "                    row += [\"NaN\"] * (len(header) - len(row))\n",
        "                elif len(row) > len(header):\n",
        "                    row = row[:len(header)]\n",
        "\n",
        "                # Replace empty strings with 'NaN'\n",
        "                cleaned_row = [col if col.strip() != \"\" else \"NaN\" for col in row]\n",
        "                rows.append(cleaned_row)\n",
        "\n",
        "        return Data(header, rows)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to use it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "source": [
        "# ---------------------------------------------------\n",
        "# Suppose you have the classes Data and DataReader\n",
        "# either in the same Python file or properly imported:\n",
        "# from my_data_lib import Data, DataReader\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# 1) Instantiate the reader\n",
        "reader = DataReader()\n",
        "\n",
        "# 2) Read the CSV file into a Data object\n",
        "data_object = reader.read_csv(\"example.csv\")  # or malformed_dataset.csv\n",
        "\n",
        "# 3) Look at the inferred data types\n",
        "print(\"Inferred dtypes:\", data_object.dtypes)\n",
        "\n",
        "# 4) Print out basic statistics for numeric columns\n",
        "stats = data_object.describe()\n",
        "print(\"\\nDescriptive statistics for numeric columns:\")\n",
        "for col_name, col_stats in stats.items():\n",
        "    print(f\"{col_name}: {col_stats}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d188dfcbde1e480b71c66e69b52162f1721e9379a92df673941419cd9e5e1b3f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
